{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "CAmxbyVeUXLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "_85Ah0w_UZmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "lDYDdPsUUavt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training dataset from multiple parts\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root='/csehome/m22cs053/RADIUS_ASSIGNMENT/imagenet/imagenet100/train.X1', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "# Load validation dataset\n",
        "val_dataset = datasets.ImageFolder(root='/csehome/m22cs053/RADIUS_ASSIGNMENT/imagenet/imagenet100/val.X', transform=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "zNRTYJDnUdKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight initialization\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.kaiming_uniform_(m.weight)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = models.resnet50(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 100)  # Adjusting for 100 classes\n",
        "model = model.to(device)\n",
        "\n",
        "model.apply(init_weights)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "SNV8ZkjsUgUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPqkheY9T_Uk"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "def train_model(num_epochs):\n",
        "    total_train_time = 0\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()  # TIME CHECK\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "        # scheduler.step()  # Update the learning rate\n",
        "        training_loss = running_loss/total\n",
        "        training_accuracy = correct/total\n",
        "        end_time = time.time()  # End time for the epoch\n",
        "        epoch_duration = end_time - start_time\n",
        "        total_train_time += epoch_duration\n",
        "        print(f'Time elapsed for epoch {epoch + 1}: {epoch_duration:.2f} seconds')\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}: Training Loss: {training_loss:.4f}, Training Accuracy: {training_accuracy:.4f}')\n",
        "        # print(f'Time elapsed for epoch {epoch + 1}: {epoch_duration:.2f} seconds')\n",
        "\n",
        "\n",
        "\n",
        "        val_loss, val_accuracy = validate_model()\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}: Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "        print(f'Epoch {epoch+1}: Model improved and saved to {model_save_path}')\n",
        "\n",
        "\n",
        "    print(f'Total training time: {total_train_time:.2f} seconds')\n",
        "\n",
        "# Validate the model\n",
        "def validate_model():\n",
        "    start_time = time.time()  # Start time for validation\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    end_time = time.time()  # End time for validation\n",
        "    validation_duration = end_time - start_time\n",
        "    print(f'Validation time: {validation_duration:.2f} seconds')\n",
        "\n",
        "    average_loss = total_loss / total\n",
        "    accuracy = correct/total\n",
        "    print(f'Average Validation Loss: {average_loss:.4f}')\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print('Classification Report:')\n",
        "    print(classification_report(all_labels, all_preds, zero_division=0))\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    print('Confusion Matrix:')\n",
        "    print(cm)\n",
        "\n",
        "    return average_loss,accuracy\n",
        "\n",
        "\n",
        "\n",
        "# Directory for saving the model\n",
        "model_save_path = '/csehome/m22cs053/RADIUS_ASSIGNMENT/saved_models/imagenet_100_resnet50_woearly.pth'\n",
        "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
        "\n",
        "# Train and validate\n",
        "num_epochs = 30  # Set the number of epochs\n",
        "train_model(num_epochs)"
      ]
    }
  ]
}